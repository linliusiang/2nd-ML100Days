{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業\n",
    "礙於不是所有同學都有 GPU ，這邊的範例使用的是簡化版本的 ResNet，確保所有同學都能夠順利訓練!\n",
    "\n",
    "\n",
    "最後一天的作業請閱讀這篇非常詳盡的[文章](https://blog.gtwang.org/programming/keras-resnet-50-pre-trained-model-build-dogs-cats-image-classification-system/)，基本上已經涵蓋了所有訓練　CNN 常用的技巧，請使用所有學過的訓練技巧，盡可能地提高 Cifar-10 的 test data 準確率，截圖你最佳的結果並上傳來完成最後一次的作業吧!\n",
    "\n",
    "另外這些技巧在 Kaggle 上也會被許多人使用，更有人會開發一些新的技巧，例如使把預訓練在 ImageNet 上的模型當成 feature extractor 後，再拿擷取出的特徵重新訓練新的模型，這些技巧再進階的課程我們會在提到，有興趣的同學也可以[參考](https://www.kaggle.com/insaff/img-feature-extraction-with-pretrained-resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "%matplotlib inline\n",
    "import keras\n",
    "from keras.applications import VGG16 \n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "# from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 # batch 的大小，如果出現 OOM error，請降低這個值\n",
    "num_classes = 10 # 類別的數量，Cifar 10 共有 10 個類別\n",
    "epochs = 30 # 訓練的 epochs 數量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# 讀取 Cifar-10 資料集\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "input_shape = x_train.shape[1:]\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立 ImageDataGenerator，並指定我們要做資料增強的數值範圍\n",
    "# rescale 將 image 做標準化\n",
    "data_generator = ImageDataGenerator(\n",
    "    rotation_range=20, # 旋轉\n",
    "    width_shift_range=0.2, # 平移\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rescale= 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1018 18:53:28.349982  7892 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1018 18:53:28.405351  7892 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1018 18:53:28.422925  7892 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W1018 18:53:28.472591  7892 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1018 18:53:28.474585  7892 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W1018 18:53:28.590265  7892 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W1018 18:53:28.708329  7892 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras_applications\\resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "ResNet50 代表我們使用從 imagenet 訓練好的參數來初始\n",
    "pooling avg 把 feature maps 變成⼀維的向量\n",
    "include_top 將原本的 Dense layer 拔掉，因為原本這個網路是用來做 1000 個分類的模型，我們必須替換成⾃己的 Dense layer 來符合我們⾃己資料集的類別數量\n",
    "'''\n",
    "# 建立 ResNet50 模型\n",
    "resnet_model = ResNet50(input_shape=input_shape,\n",
    "                        weights='imagenet',\n",
    "                        include_top=False)\n",
    "# # 建立VGG16模型\n",
    "# conv_vgg = VGG16(weights = 'imagenet',\n",
    "#                  include_top = False,\n",
    "#                  input_shape = input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 1, 1, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 24,114,826\n",
      "Trainable params: 24,061,706\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(resnet_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1018 18:53:57.542183  7892 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1018 18:53:57.821151  7892 deprecation.py:323] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "781/781 [==============================] - 2562s 3s/step - loss: 2.1779 - acc: 0.2422 - val_loss: 2.0469 - val_acc: 0.2841\n",
      "Epoch 2/30\n",
      "781/781 [==============================] - 2445s 3s/step - loss: 1.7558 - acc: 0.3431 - val_loss: 1.5789 - val_acc: 0.4172\n",
      "Epoch 3/30\n",
      "781/781 [==============================] - 2422s 3s/step - loss: 1.4974 - acc: 0.4411 - val_loss: 1.4877 - val_acc: 0.4622\n",
      "Epoch 4/30\n",
      "781/781 [==============================] - 2414s 3s/step - loss: 1.3467 - acc: 0.5094 - val_loss: 1.5034 - val_acc: 0.4686\n",
      "Epoch 5/30\n",
      "781/781 [==============================] - 2412s 3s/step - loss: 1.2003 - acc: 0.5693 - val_loss: 1.2679 - val_acc: 0.5831\n",
      "Epoch 6/30\n",
      "781/781 [==============================] - 2408s 3s/step - loss: 1.2414 - acc: 0.5569 - val_loss: 3.2053 - val_acc: 0.1572\n",
      "Epoch 7/30\n",
      "781/781 [==============================] - 2414s 3s/step - loss: 1.5565 - acc: 0.4290 - val_loss: 1.3980 - val_acc: 0.5006\n",
      "Epoch 8/30\n",
      "781/781 [==============================] - 2419s 3s/step - loss: 1.3452 - acc: 0.5157 - val_loss: 1.2665 - val_acc: 0.5606\n",
      "Epoch 9/30\n",
      "781/781 [==============================] - 2412s 3s/step - loss: 1.2433 - acc: 0.5577 - val_loss: 2.8147 - val_acc: 0.2097\n",
      "Epoch 10/30\n",
      "781/781 [==============================] - 2413s 3s/step - loss: 1.3946 - acc: 0.4979 - val_loss: 2.7687 - val_acc: 0.2947\n",
      "Epoch 11/30\n",
      "781/781 [==============================] - 2417s 3s/step - loss: 1.3923 - acc: 0.4972 - val_loss: 1.2551 - val_acc: 0.5487\n",
      "Epoch 12/30\n",
      "781/781 [==============================] - 2415s 3s/step - loss: 1.2241 - acc: 0.5695 - val_loss: 1.0851 - val_acc: 0.6150\n",
      "Epoch 13/30\n",
      "781/781 [==============================] - 2412s 3s/step - loss: 1.1443 - acc: 0.5951 - val_loss: 1.0571 - val_acc: 0.6225\n",
      "Epoch 14/30\n",
      "781/781 [==============================] - 2455s 3s/step - loss: 1.2308 - acc: 0.5635 - val_loss: 1.1806 - val_acc: 0.5750\n",
      "Epoch 15/30\n",
      "781/781 [==============================] - 2445s 3s/step - loss: 1.2860 - acc: 0.5404 - val_loss: 1.1769 - val_acc: 0.5763\n",
      "Epoch 16/30\n",
      "781/781 [==============================] - 2413s 3s/step - loss: 1.1810 - acc: 0.5807 - val_loss: 1.1133 - val_acc: 0.6177\n",
      "Epoch 17/30\n",
      "781/781 [==============================] - 2415s 3s/step - loss: 1.2276 - acc: 0.5676 - val_loss: 1.3875 - val_acc: 0.5944\n",
      "Epoch 18/30\n",
      "781/781 [==============================] - 2413s 3s/step - loss: 1.2116 - acc: 0.5825 - val_loss: 1.3293 - val_acc: 0.5628\n",
      "Epoch 19/30\n",
      "781/781 [==============================] - 2414s 3s/step - loss: 1.0098 - acc: 0.6489 - val_loss: 0.9040 - val_acc: 0.6701\n",
      "Epoch 20/30\n",
      "781/781 [==============================] - 2412s 3s/step - loss: 0.9367 - acc: 0.6735 - val_loss: 1.1088 - val_acc: 0.6181\n",
      "Epoch 21/30\n",
      "781/781 [==============================] - 2418s 3s/step - loss: 0.9073 - acc: 0.6851 - val_loss: 1.1968 - val_acc: 0.6069\n",
      "Epoch 22/30\n",
      "781/781 [==============================] - 2412s 3s/step - loss: 0.8982 - acc: 0.6914 - val_loss: 0.9598 - val_acc: 0.6796\n",
      "Epoch 23/30\n",
      "781/781 [==============================] - 2415s 3s/step - loss: 0.8526 - acc: 0.7056 - val_loss: 1.5881 - val_acc: 0.5600\n",
      "Epoch 24/30\n",
      "781/781 [==============================] - 2413s 3s/step - loss: 0.8122 - acc: 0.7192 - val_loss: 0.8578 - val_acc: 0.7050\n",
      "Epoch 25/30\n",
      "781/781 [==============================] - 2437s 3s/step - loss: 0.8851 - acc: 0.6980 - val_loss: 1.0863 - val_acc: 0.6194\n",
      "Epoch 26/30\n",
      "781/781 [==============================] - 2429s 3s/step - loss: 0.8066 - acc: 0.7215 - val_loss: 0.7740 - val_acc: 0.7351\n",
      "Epoch 27/30\n",
      "781/781 [==============================] - 2417s 3s/step - loss: 0.7701 - acc: 0.7352 - val_loss: 0.9460 - val_acc: 0.6872\n",
      "Epoch 28/30\n",
      "781/781 [==============================] - 2414s 3s/step - loss: 0.7360 - acc: 0.7460 - val_loss: 0.8897 - val_acc: 0.7144\n",
      "Epoch 29/30\n",
      "781/781 [==============================] - 2419s 3s/step - loss: 0.7233 - acc: 0.7517 - val_loss: 1.0237 - val_acc: 0.6618\n",
      "Epoch 30/30\n",
      "781/781 [==============================] - 2419s 3s/step - loss: 0.8570 - acc: 0.7045 - val_loss: 0.8102 - val_acc: 0.7269\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17dde8d3dd8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "已經設定成沒有 Dense layers，且最後⼀層做 GAP\n",
    "使⽤resnet_model.output 可以取出最後一層的 featuremaps\n",
    "使⽤ Flatten 攤平後，再接上 Dense layer，神經元數量與資料集的類別數量⼀致\n",
    "建立模型可以得到一個新的 ResNet-50 模型，且參數是根據 ImageNet 資料集預訓練好的\n",
    "'''\n",
    "# last_map = resnet_model.output\n",
    "# # flatten_map = Flatten()(last_map)\n",
    "# output = Dense(num_classes)(last_map)\n",
    "\n",
    "# model = Model(inputs=resnet_model.input, outputs=output)\n",
    "\n",
    "model.compile(optimizer=Adam(),\n",
    "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(data_generator.flow(x_train, y_train, batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=test_generator.flow(x_test, y_test, batch_size=batch_size),\n",
    "                        steps_per_epoch=int(len(x_train)//batch_size),\n",
    "                        validation_steps = 50,\n",
    "                        workers=4)\n",
    "\n",
    "# score = model.evaluate(x_test, y_test, verbose=0)\n",
    "# print('Test loss:', score[0])\n",
    "# print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.8117351828575134\n",
      "Test accuracy: 0.7243\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test/255, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
